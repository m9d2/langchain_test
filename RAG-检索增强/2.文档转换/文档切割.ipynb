{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档切割\n",
    "\n",
    "### 原理\n",
    "\n",
    "1.将文档分成小的有意义的快（句子）。\n",
    "\n",
    "2.将小的快组合成更大的块，直到达到一定的大小\n",
    "\n",
    "3.一旦到达一定的大小，接着创建与下一个块重叠的部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例\n",
    "\n",
    "- 按字符切割\n",
    "- 代码文档切割\n",
    "- 按Token分割文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按字符切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open(\"input.txt\") as f:\n",
    "    text = f.read()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=\"。\", # 切割的标识字符，默认为\\n\\r\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([text])\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码文档切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    Language\n",
    ")\n",
    "\n",
    "#支持解析的编程语言有\n",
    "[e.value for e in Language]\n",
    "\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# 调用函数  \n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "py_spiller = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "python_doc = py_spiller.create_documents([PYTHON_CODE])\n",
    "python_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按Token分割文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "with open(\"input.txt\") as f:\n",
    "    text = f.read()\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([text])\n",
    "texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
